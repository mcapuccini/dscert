{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37064bitbaseconda7a6f723de0684a4e8ef69102fcac7d81",
   "display_name": "Python 3.7.0 64-bit ('base': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to workspace\n",
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Property base_image is mutually exclusive with base_dockerfile. Reset base_image to None\n"
     ]
    }
   ],
   "source": [
    "# Create Docker environment\n",
    "from azureml.core import Environment\n",
    "\n",
    "myenv = Environment(name=\"myenv\")\n",
    "myenv.docker.enabled = True\n",
    "with open(\"Dockerfile\", \"r\") as f:\n",
    "    dockerfile=f.read()\n",
    "myenv.docker.base_dockerfile = dockerfile\n",
    "myenv.python.user_managed_dependencies = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning, custom base image or base dockerfile detected without a specified `inferencing_stack_version`. Please set environment.inferencing_stack_version='latest'\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "classifier_inference_config = InferenceConfig(source_directory = \"scripts\",\n",
    "                                              entry_script=\"entry_script.py\",\n",
    "                                              environment=myenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating...........................................................................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# Deploy a k8s\n",
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "\n",
    "cluster_name = 'inference-k8s'\n",
    "compute_config = AksCompute.provisioning_configuration(\n",
    "    cluster_purpose='DevTest',\n",
    "    vm_size='Standard_D11_v2',\n",
    "    agent_count=2,\n",
    "    location='westeurope')\n",
    "production_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "production_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure service\n",
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "classifier_deploy_config = AksWebservice.deploy_configuration(cpu_cores = 1,\n",
    "                                                              memory_gb = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running............................................................................................................................................................\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# Deploy!!!\n",
    "from azureml.core.model import Model\n",
    "\n",
    "model = ws.models['diabetes_model']\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name = 'diabetes-serv',\n",
    "                       models = [model],\n",
    "                       inference_config = classifier_inference_config,\n",
    "                       deployment_config = classifier_deploy_config,\n",
    "                       deployment_target = production_cluster)\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 1]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Auth\n",
    "primary_key, secondary_key = service.get_keys()\n",
    "\n",
    "# An array of new data cases\n",
    "x_new = [[6,148,72,35,0,33.6,0.627,50],\n",
    "         [11,138,76,0,0,33.2,0.42,35]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "json_data = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type in the request headers\n",
    "request_headers = { \"Content-Type\":\"application/json\",\n",
    "                    \"Authorization\":\"Bearer \" + primary_key}\n",
    "\n",
    "# Call the service\n",
    "response = requests.post(url = 'http://23.100.12.190:80/api/v1/service/diabetes-serv/score',\n",
    "                         data = json_data,\n",
    "                         headers = request_headers)\n",
    "\n",
    "# Get the predictions from the JSON response\n",
    "print(response.json())"
   ]
  }
 ]
}