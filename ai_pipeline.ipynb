{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37064bitbaseconda3e2eb03802ea4deb86c373ab1bdf986a",
   "display_name": "Python 3.7.0 64-bit ('base': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login\n",
    "!az login > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to workspace\n",
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Property base_image is mutually exclusive with base_dockerfile. Reset base_image to None\n",
      "Created step prepare data [9dd6af5c][514f9074-68b6-44b7-ae6d-7d9ec5bc9ed3], (This step is eligible to reuse a previous run's output)\n",
      "Created step train [0d183bf4][88ef328b-77ad-49a7-9d3c-cfe4ed24899d], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 1bd19708-269a-4325-8cb8-0f5c1eb79501\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-pipeline/runs/1bd19708-269a-4325-8cb8-0f5c1eb79501?wsid=/subscriptions/1bd4017e-d44c-46ab-9e6d-400b8d5f3da8/resourcegroups/ds_cert/workspaces/dscert\n"
     ]
    }
   ],
   "source": [
    "# Pipeline\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core import Experiment, Environment, RunConfiguration\n",
    "\n",
    "# Define a PipelineData object to pass data between steps\n",
    "data_store = ws.get_default_datastore()\n",
    "prepped_data = PipelineData('prepped',  datastore=data_store)\n",
    "\n",
    "# Setup Docker environment\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment.docker.enabled = True\n",
    "with open(\"Dockerfile\", \"r\") as f:\n",
    "    dockerfile=f.read()\n",
    "run_config.environment.docker.base_dockerfile = dockerfile\n",
    "run_config.environment.python.user_managed_dependencies = True\n",
    "\n",
    "# Step to run a Python script\n",
    "step1 = PythonScriptStep(name = 'prepare data',\n",
    "                         source_directory = 'scripts',\n",
    "                         script_name = 'diabetes_prepare.py',\n",
    "                         compute_target = 'nossh',\n",
    "                         runconfig = run_config,\n",
    "                         # Script arguments include PipelineData\n",
    "                         arguments = ['--ds-name', 'diabetes',\n",
    "                                      '--out', prepped_data],\n",
    "                         # Specify PipelineData as output\n",
    "                         outputs=[prepped_data])\n",
    "\n",
    "step2 = PythonScriptStep(name = 'train',\n",
    "                         source_directory = 'scripts',\n",
    "                         script_name = 'diabetes_train.py',\n",
    "                         compute_target = 'nossh',\n",
    "                         runconfig = run_config,\n",
    "                         # Script arguments include PipelineData\n",
    "                         arguments = ['--split-dir', prepped_data],\n",
    "                         # Specify PipelineData as input\n",
    "                         inputs=[prepped_data])\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline = Pipeline(workspace = ws, steps = [step1, step2])\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace = ws, name = 'diabetes-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/1bd4017e-d44c-46ab-9e6d-400b8d5f3da8/resourceGroups/ds_cert/providers/Microsoft.MachineLearningServices/workspaces/dscert/PipelineRuns/PipelineSubmit/320249d3-cff0-42f7-ab71-55bf26d288c3\n"
     ]
    }
   ],
   "source": [
    "# Publish pipeline\n",
    "published_pipeline = pipeline.publish(name='diabetes',\n",
    "                                      description='Model training pipeline',\n",
    "                                      version='1.0')\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule every day\n",
    "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
    "\n",
    "daily = ScheduleRecurrence(frequency='Day', interval=1)\n",
    "pipeline_schedule = Schedule.create(ws, name='Daily Training',\n",
    "                                        description='trains model every day',\n",
    "                                        pipeline_id=published_pipeline.id,\n",
    "                                        experiment_name='Training_Pipeline',\n",
    "                                        recurrence=daily)"
   ]
  }
 ]
}